{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_lenet_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgQu7mddkhpnohESToVsND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shraddha-an/cnns/blob/master/mnist_lenet_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixio7Lg6uvYF"
      },
      "source": [
        "# PyTorch CNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Setting random seeds for reproducibility\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Setting device\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVt4Z0bwu29C",
        "outputId": "d8d19c17-e4ca-46b0-9ea2-2a084c93240c"
      },
      "source": [
        "ROOT = '.data'\n",
        "\n",
        "train_data = datasets.MNIST(root = ROOT, \n",
        "                            train = True, \n",
        "                            download = True)\n",
        "\n",
        "mean = train_data.data.float().mean() / 255\n",
        "std = train_data.data.float().std() / 255\n",
        "\n",
        "print(f'Calculated mean: {mean}')\n",
        "print(f'Calculated std: {std}')\n",
        "\n",
        "# Setting up transforms pipelines for training/testing data\n",
        "train_transforms = transforms.Compose([\n",
        "                            transforms.RandomRotation(5, fill=(0,)),\n",
        "                            transforms.RandomCrop(28, padding = 2),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize(mean = [mean], std = [std])\n",
        "                                      ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = [mean], std = [std])\n",
        "                                     ])\n",
        "\n",
        "\n",
        "# Applying transforms on data\n",
        "train_data = datasets.MNIST(root = ROOT, \n",
        "                            train = True, \n",
        "                            download = True, \n",
        "                            transform = train_transforms)\n",
        "\n",
        "test_data = datasets.MNIST(root = ROOT, \n",
        "                           train = False, \n",
        "                           download = True, \n",
        "                           transform = test_transforms)\n",
        "\n",
        "# Creating validation data- 10 % from training data\n",
        "VALID_RATIO = 0.9\n",
        "\n",
        "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "n_valid_examples = len(train_data) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(train_data, \n",
        "                                           [n_train_examples, n_valid_examples])\n",
        "\n",
        "# Stripping the train transforms on validation data & applying test transforms\n",
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms\n",
        "\n",
        "# Creating data loader objects\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator = data.DataLoader(train_data, \n",
        "                                 shuffle = True, \n",
        "                                 batch_size = BATCH_SIZE)\n",
        "\n",
        "valid_iterator = data.DataLoader(valid_data, \n",
        "                                 batch_size = BATCH_SIZE)\n",
        "\n",
        "test_iterator = data.DataLoader(test_data, \n",
        "                                batch_size = BATCH_SIZE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculated mean: 0.13066047430038452\n",
            "Calculated std: 0.30810779333114624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXhLXhV-wSVG",
        "outputId": "0db109be-d1e5-4f16-afe7-3e037a824c02"
      },
      "source": [
        "# Creating the model\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, \n",
        "                               out_channels = 6, \n",
        "                               kernel_size = 5)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels = 6, \n",
        "                               out_channels = 16, \n",
        "                               kernel_size = 5)\n",
        "        \n",
        "        self.fc_1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc_2 = nn.Linear(120, 84)\n",
        "        self.fc_3 = nn.Linear(84, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #x = [batch size, 1, 28, 28]\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        \n",
        "        #x = [batch size, 6, 24, 24]\n",
        "        \n",
        "        x = F.max_pool2d(x, kernel_size = 2)\n",
        "        \n",
        "        #x = [batch size, 6, 12, 12]\n",
        "        \n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        \n",
        "        #x = [batch size, 16, 8, 8]\n",
        "        \n",
        "        x = F.max_pool2d(x, kernel_size = 2)\n",
        "        \n",
        "        #x = [batch size, 16, 4, 4]\n",
        "        \n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        #x = [batch size, 16*4*4 = 256]\n",
        "        \n",
        "        h = x\n",
        "        \n",
        "        x = self.fc_1(x)\n",
        "        \n",
        "        #x = [batch size, 120]\n",
        "        \n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = batch size, 84]\n",
        "        \n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.fc_3(x)\n",
        "\n",
        "        #x = [batch size, output dim]\n",
        "        \n",
        "        return x, h\n",
        "\n",
        "# CReating an instance of the LeNet model\n",
        "OUTPUT_DIM = 10\n",
        "\n",
        "model = LeNet(OUTPUT_DIM)\n",
        "model.to(device)\n",
        "print(model)        \n",
        "\n",
        "# Optimizer\n",
        "from torch import optim\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Criterion/loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Accuracy\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc_1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc_2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc_3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w_8EcwVyioL"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for (x, y) in iterator:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        y_pred, _ = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHXk2mMGyp8S",
        "outputId": "9d5a9b02-cf03-4f02-ab04-09d2b9af134a"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    print('Epoch {}/{}'.format(epoch+1, EPOCHS))\n",
        "    print('---' * 10)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.031 | Train Acc: 99.01%\n",
            "\t Val. Loss: 0.031 |  Val. Acc: 99.03%\n",
            "Epoch 2/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.033 | Train Acc: 98.97%\n",
            "\t Val. Loss: 0.033 |  Val. Acc: 99.06%\n",
            "Epoch 3/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.029 | Train Acc: 99.05%\n",
            "\t Val. Loss: 0.027 |  Val. Acc: 99.27%\n",
            "Epoch 4/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.031 | Train Acc: 99.05%\n",
            "\t Val. Loss: 0.029 |  Val. Acc: 99.18%\n",
            "Epoch 5/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.030 | Train Acc: 99.05%\n",
            "\t Val. Loss: 0.033 |  Val. Acc: 99.12%\n",
            "Epoch 6/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.13%\n",
            "\t Val. Loss: 0.035 |  Val. Acc: 99.09%\n",
            "Epoch 7/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.030 | Train Acc: 99.08%\n",
            "\t Val. Loss: 0.029 |  Val. Acc: 99.12%\n",
            "Epoch 8/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.11%\n",
            "\t Val. Loss: 0.030 |  Val. Acc: 99.18%\n",
            "Epoch 9/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.028 | Train Acc: 99.12%\n",
            "\t Val. Loss: 0.031 |  Val. Acc: 99.09%\n",
            "Epoch 10/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.19%\n",
            "\t Val. Loss: 0.030 |  Val. Acc: 99.11%\n",
            "Epoch 11/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.026 | Train Acc: 99.17%\n",
            "\t Val. Loss: 0.036 |  Val. Acc: 98.94%\n",
            "Epoch 12/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.15%\n",
            "\t Val. Loss: 0.035 |  Val. Acc: 99.13%\n",
            "Epoch 13/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.20%\n",
            "\t Val. Loss: 0.031 |  Val. Acc: 99.16%\n",
            "Epoch 14/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.22%\n",
            "\t Val. Loss: 0.036 |  Val. Acc: 99.04%\n",
            "Epoch 15/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.026 | Train Acc: 99.16%\n",
            "\t Val. Loss: 0.035 |  Val. Acc: 98.99%\n",
            "Epoch 16/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.18%\n",
            "\t Val. Loss: 0.033 |  Val. Acc: 99.18%\n",
            "Epoch 17/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.024 | Train Acc: 99.24%\n",
            "\t Val. Loss: 0.036 |  Val. Acc: 99.19%\n",
            "Epoch 18/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.23%\n",
            "\t Val. Loss: 0.030 |  Val. Acc: 99.06%\n",
            "Epoch 19/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.16%\n",
            "\t Val. Loss: 0.034 |  Val. Acc: 99.16%\n",
            "Epoch 20/20\n",
            "------------------------------\n",
            "\tTrain Loss: 0.023 | Train Acc: 99.20%\n",
            "\t Val. Loss: 0.036 |  Val. Acc: 98.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK19HUZRy4lu",
        "outputId": "4ad7a6d3-0b1e-4241-b8d8-26e084fbcec3"
      },
      "source": [
        "# Testing on test set\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.024 | Test Acc: 99.25%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}