{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V-dPHKPYP1mT",
        "DPlZUf-OUX8c",
        "Ekpjtb1LVf8v",
        "cGrnl-MoV-g3"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONV1vNSzzcW3VDlc98N8bm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shraddha-an/cnns/blob/master/image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvJyALoWyfhb",
        "colab_type": "text"
      },
      "source": [
        "Image Classification with CNN - Cats vs Owls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duNTwHF7Pw42",
        "colab_type": "text"
      },
      "source": [
        "# 1) Introduction\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-dPHKPYP1mT",
        "colab_type": "text"
      },
      "source": [
        "#### **Skills Demonstrated**: Data Collection, Image Augmentation, Deep Learning, Image Classification, Web Scraping.\n",
        "\n",
        "\n",
        "In this Deep Learning Project, I built a CNN to classify images of cats and owls.\n",
        "\n",
        "\n",
        "I wrote a Python script to download photos of cats and owls from Flickr using the [flickrapi](https://github.com/sybrenstuvel/flickrapi) and the urllib library.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzps3VWyPs4N",
        "colab_type": "text"
      },
      "source": [
        "# 2) Data Collection\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5L0rF5PSo0s",
        "colab_type": "text"
      },
      "source": [
        "To use the Flickr API service, you'll have to apply for an API Authentication key [here](https://www.flickr.com/services/api/misc.api_keys.html).\n",
        "\n",
        "\n",
        "\n",
        "1.  Download the flickrapi library\n",
        "    ```\n",
        "    pip install flickrapi\n",
        "    ```\n",
        "\n",
        "2.  Download the urllib library\n",
        "    ```\n",
        "    pip install urllib\n",
        "    ```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7h-nsB6UOWv",
        "colab_type": "text"
      },
      "source": [
        "### a) Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqRNtykIypyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "import flickrapi\n",
        "\n",
        "from time import sleep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KknuQVGvUUi-",
        "colab_type": "text"
      },
      "source": [
        "### b) API Authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcXvRQL_To8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To authenticate, plug in your API Key as the first argument and the Secret Code as the second.\n",
        "flickr = flickrapi.FlickrAPI('API_Key', 'Secret_code', cache = True)\n",
        "\n",
        "# Getting the photos through the walk method\n",
        "cat_photos = flickr.walk(text = 'cat',\n",
        "                     tag_mode = 'all',\n",
        "                     tags = 'cat',\n",
        "                     extras = 'url_c',\n",
        "                     per_page = 1000,\n",
        "                     sort = 'relevance')\n",
        "\n",
        "owl_photos = flickr.walk(text = 'owl',\n",
        "                     tag_mode = 'all',\n",
        "                     tags = 'owl',\n",
        "                     extras = 'url_c',\n",
        "                     per_page = 1000,\n",
        "                     sort = 'relevance')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPlZUf-OUX8c",
        "colab_type": "text"
      },
      "source": [
        "### c) Downloading Images\n",
        "Create a train and a test folder. Inside each of the 2 folders, create 2 more folders and name them cat and owl.\n",
        "\n",
        "Make sure to download the cat images into the cat folder and the owl images into the owl folder.\n",
        "\n",
        "After the images have been downloaded, move 10 images each of cats & owls from the train folder to the test folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5bcw8NqUKm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting URLs of photos from the response\n",
        "cat_urls = []\n",
        "for i, photo in enumerate(cat_photos):\n",
        "\n",
        "    cat_urls.append(photo.get('url_c'))\n",
        "\n",
        "    # get 1000 urls\n",
        "    if i > 1050:\n",
        "        break\n",
        "\n",
        "owl_urls = []\n",
        "for i, photo in enumerate(owl_photos):\n",
        "\n",
        "    owl_urls.append(photo.get('url_c'))\n",
        "\n",
        "    # get 1000 urls\n",
        "    if i > 1050:\n",
        "        break\n",
        "\n",
        "\n",
        "# Removing None type objects & taking only the first 960 URLs. 950 images for training & 10 images for testing\n",
        "cat_urls = [x for x in cat_urls if x is not None][:960]\n",
        "owl_urls = [x for x in owl_urls if x is not None][:960]\n",
        "\n",
        "# =====================================  Downloading the images to folders ==========================================\n",
        "# 1) Cat Images\n",
        "for count, url in enumerate(cat_urls[:480]):\n",
        "    urllib.request.urlretrieve(url, 'training_folder_path/cat'+ str(count) + '.jpg')\n",
        "\n",
        "sleep(100)\n",
        "\n",
        "for count, url in enumerate(cat_urls[480:]):\n",
        "    urllib.request.urlretrieve(url, 'training_folder_path/cat'+ str(480 + count) + '.jpg')\n",
        "\n",
        "# Owl Images\n",
        "for count, url in enumerate(owl_urls[:480]):\n",
        "    urllib.request.urlretrieve(url, 'training_folder_path/owl'+ str(count) + '.jpg')\n",
        "\n",
        "sleep(100)\n",
        "\n",
        "for count, url in enumerate(owl_urls[480: ]):\n",
        "    urllib.request.urlretrieve(url, 'training_folder_path/owl'+ str(450 + count) + '.jpg')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekpjtb1LVf8v",
        "colab_type": "text"
      },
      "source": [
        "# 3) CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOnkgf6YVlGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Sequential model and layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(300, 300, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding = 'same'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'rmsprop',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "batch_size = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGrnl-MoV-g3",
        "colab_type": "text"
      },
      "source": [
        "# 4) Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPHohpZUWDGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Augmentation configuration\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Testing Augmentation - Only Rescaling\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# Generates batches of Augmented Image data\n",
        "train_generator = train_datagen.flow_from_directory('train/', target_size = (300, 300), \n",
        "                                                    batch_size = batch_size,\n",
        "                                                    class_mode = 'binary') \n",
        "\n",
        "# Generator for validation data\n",
        "validation_generator = test_datagen.flow_from_directory('test/', \n",
        "                                                        target_size = (300, 300),\n",
        "                                                        batch_size = batch_size,\n",
        "                                                        class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKkHWOpPW9rn",
        "colab_type": "text"
      },
      "source": [
        "# 5) Training & Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr9N72gwW_fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(train_generator,\n",
        "                    epochs = 5,\n",
        "                    validation_data = validation_generator,\n",
        "                    verbose = 1)\n",
        "\n",
        "# Evaluating model performance on Testing data\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "\n",
        "print('\\nAccuracy: ', accuracy, '\\nLoss: ', loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}